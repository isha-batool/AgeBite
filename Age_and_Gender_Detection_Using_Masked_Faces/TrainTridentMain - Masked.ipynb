{"cells":[{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":148,"status":"ok","timestamp":1624054305187,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"ag2kCPtZFBAH"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","import numpy as np\n","# torch imports\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1624052399780,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"UVr-wVukIkfA"},"outputs":[],"source":["class UTKDataset(Dataset):\n","    '''\n","        Inputs:\n","            dataFrame : Pandas dataFrame\n","            transform : The transform to apply to the dataset\n","    '''\n","    def __init__(self, dataFrame, transform=None):\n","        # read in the transforms\n","        self.transform = transform\n","        \n","        # Use the dataFrame to get the pixel values\n","        data_holder = dataFrame.pixels.apply(lambda x: np.array(x.split(\" \"),dtype=float))\n","        arr = np.stack(data_holder)\n","        arr = arr / 255.0\n","        arr = arr.astype('float32')\n","        arr = arr.reshape(arr.shape[0], 48, 48, 1)\n","        # reshape into 48x48x1\n","        self.data = arr\n","        \n","        # get the age, gender, and ethnicity label arrays\n","        self.age_label = np.array(dataFrame.bins[:])        # Note : Changed dataFrame.age to dataFrame.bins with most recent change\n","        self.gender_label = np.array(dataFrame.gender[:])\n","        self.eth_label = np.array(dataFrame.ethnicity[:])\n","    \n","    # override the length function\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    # override the getitem function\n","    def __getitem__(self, index):\n","        # load the data at index and apply transform\n","        data = self.data[index]\n","        data = self.transform(data)\n","        \n","        # load the labels into a list and convert to tensors\n","        labels = torch.tensor((self.age_label[index], self.gender_label[index], self.eth_label[index]))\n","        \n","        # return data labels\n","        return data, labels"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":239,"status":"ok","timestamp":1624052401669,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"cxkn0VdIIlQO"},"outputs":[],"source":["# High level feature extractor network (Adopted VGG type structure)\n","class highLevelNN(nn.Module):\n","    def __init__(self):\n","        super(highLevelNN, self).__init__()\n","        self.CNN = nn.Sequential(\n","            # first batch (32)\n","            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","\n","            # second batch (64)\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","\n","            # Third Batch (128)\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","\n","    def forward(self, x):\n","        out = self.CNN(x)\n","\n","        return out\n","\n","# Low level feature extraction module\n","class lowLevelNN(nn.Module):\n","    def __init__(self, num_out):\n","        super(lowLevelNN, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n","        self.fc1 = nn.Linear(in_features=2048, out_features=256)\n","        self.fc2 = nn.Linear(in_features=256, out_features=128)\n","        self.fc3 = nn.Linear(in_features=128, out_features=64)\n","        self.fc4 = nn.Linear(in_features=64, out_features=num_out)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=2, padding=1))\n","        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=3, stride=2, padding=1))\n","        x = torch.flatten(x, start_dim=1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = self.fc4(x)\n","\n","        return x\n","\n","\n","class TridentNN(nn.Module):\n","    def __init__(self, num_age, num_gen, num_eth):\n","        super(TridentNN, self).__init__()\n","        # Construct the high level neural network\n","        self.CNN = highLevelNN()\n","        # Construct the low level neural networks\n","        self.ageNN = lowLevelNN(num_out=num_age)\n","        self.genNN = lowLevelNN(num_out=num_gen)\n","        self.ethNN = lowLevelNN(num_out=num_eth)\n","\n","    def forward(self, x):\n","        x = self.CNN(x)\n","        age = self.ageNN(x)\n","        gen = self.genNN(x)\n","        eth = self.ethNN(x)\n","\n","        return age, gen, eth"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":190,"status":"ok","timestamp":1624054659108,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"S78Li3j0JeB8"},"outputs":[],"source":["'''\n","    Function to test the trained model\n","\n","    Inputs:\n","      - testloader : PyTorch DataLoader containing the test dataset\n","      - modle : Trained NeuralNetwork\n","    \n","    Outputs:\n","      - Prints out test accuracy for gender and ethnicity and loss for age\n","'''\n","def test(testloader, model):\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu' \n","  size = len(testloader.dataset)\n","  # put the moel in evaluation mode so we aren't storing anything in the graph\n","  model.eval()\n","\n","  age_acc, gen_acc, eth_acc = 0, 0, 0\n","\n","  with torch.no_grad():\n","      for X, y in testloader:\n","          X = X.to(device)\n","          age, gen, eth = y[:,0].to(device), y[:,1].to(device), y[:,2].to(device)\n","          pred = model(X)\n","\n","          age_acc += (pred[0].argmax(1) == age).type(torch.float).sum().item()\n","          gen_acc += (pred[1].argmax(1) == gen).type(torch.float).sum().item()\n","          eth_acc += (pred[2].argmax(1) == eth).type(torch.float).sum().item()\n","\n","  age_acc /= size\n","  gen_acc /= size\n","  eth_acc /= size\n","\n","  print(f\"Age Accuracy : {age_acc*100}%,     Gender Accuracy : {gen_acc*100},    Ethnicity Accuracy : {eth_acc*100}\\n\")"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11082,"status":"ok","timestamp":1624053963605,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"r9QWQfreI_qW","outputId":"017215ff-675b-437b-c638-c4dcf72641be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of training X: torch.Size([64, 1, 48, 48])\n","Shape of y: torch.Size([64, 3])\n"]}],"source":["# Read in the dataframe\n","dataFrame = pd.read_csv(r'..\\age_gender.gz', compression='gzip')\n"," \n","# Construct age bins\n","age_bins = [0,10,15,20,25,30,40,50,60,120]\n","age_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n","dataFrame['bins'] = pd.cut(dataFrame.age, bins=age_bins, labels=age_labels)\n","\n","# Split into training and testing\n","train_dataFrame, test_dataFrame = train_test_split(dataFrame, test_size=0.2)\n","\n","# get the number of unique classes for each group\n","class_nums = {'age_num':len(dataFrame['bins'].unique()), 'eth_num':len(dataFrame['ethnicity'].unique()),\n","              'gen_num':len(dataFrame['gender'].unique())}\n","\n","# Define train and test transforms\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.49,), (0.23,))\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.49,), (0.23,))\n","])\n","\n","# Construct the custom pytorch datasets\n","train_set = UTKDataset(train_dataFrame, transform=train_transform)\n","test_set = UTKDataset(test_dataFrame, transform=test_transform)\n","\n","# Load the datasets into dataloaders\n","trainloader = DataLoader(train_set, batch_size=64, shuffle=True)\n","testloader = DataLoader(test_set, batch_size=128, shuffle=False)\n","\n","# Sanity Check\n","for X, y in trainloader:\n","    print(f'Shape of training X: {X.shape}')\n","    print(f'Shape of y: {y.shape}')\n","    break "]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1624053999222,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"KHME6XaiB4RA","outputId":"a410ed61-bd19-484b-d55c-a5c252d4b162"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]},{"data":{"text/plain":["TridentNN(\n","  (CNN): highLevelNN(\n","    (CNN): Sequential(\n","      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU()\n","      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (4): ReLU()\n","      (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (6): ReLU()\n","      (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (9): ReLU()\n","      (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (11): ReLU()\n","      (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (13): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (14): ReLU()\n","    )\n","  )\n","  (ageNN): lowLevelNN(\n","    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fc1): Linear(in_features=2048, out_features=256, bias=True)\n","    (fc2): Linear(in_features=256, out_features=128, bias=True)\n","    (fc3): Linear(in_features=128, out_features=64, bias=True)\n","    (fc4): Linear(in_features=64, out_features=9, bias=True)\n","  )\n","  (genNN): lowLevelNN(\n","    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fc1): Linear(in_features=2048, out_features=256, bias=True)\n","    (fc2): Linear(in_features=256, out_features=128, bias=True)\n","    (fc3): Linear(in_features=128, out_features=64, bias=True)\n","    (fc4): Linear(in_features=64, out_features=2, bias=True)\n","  )\n","  (ethNN): lowLevelNN(\n","    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fc1): Linear(in_features=2048, out_features=256, bias=True)\n","    (fc2): Linear(in_features=256, out_features=128, bias=True)\n","    (fc3): Linear(in_features=128, out_features=64, bias=True)\n","    (fc4): Linear(in_features=64, out_features=5, bias=True)\n","  )\n",")"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Configure the device \n","device = 'cuda' if torch.cuda.is_available() else 'cpu' \n","print(device)\n","\n","# Define the list of hyperparameters\n","hyperparameters = {'learning_rate':0.001, 'epochs':30}\n","\n","# Initialize the TridentNN model and put on device\n","model = TridentNN(class_nums['age_num'], class_nums['gen_num'], class_nums['eth_num'])\n","model.to(device)"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":146,"status":"ok","timestamp":1624054001685,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"M1e1Yf_bE2bt"},"outputs":[],"source":["'''\n","  Functions to load and save a PyTorch model\n","'''\n","def save_checkpoint(state, epoch):\n","  print(\"Saving Checkpoint\")\n","  filename = \"tridentNN_epoch\"+str(epoch)+\".pth.tar\"\n","  torch.save(state,filename)\n","\n","def load_checkpoint(checkpoint):\n","  print(\"Loading Checkpoint\")\n","  model.load_state_dict(checkpoint['state_dict'])\n","  opt.load_state_dict(checkpoint['optimizer'])\n"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":253766,"status":"error","timestamp":1624054575708,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"FGdpJIvvJZWk","outputId":"87e7214d-35c1-4bec-a921-209981ab7862"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/297 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Saving Checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [1/30]: 100%|██████████| 297/297 [04:43<00:00,  1.05it/s, loss=3.61]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 1/30,    Age Accuracy : 22.685087534275468,    Gender Accuracy : 59.881881459607676,    Ethnicity Accuracy : 44.38936933136469\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [2/30]: 100%|██████████| 297/297 [04:40<00:00,  1.06it/s, loss=2.81]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 2/30,    Age Accuracy : 36.50601139000211,    Gender Accuracy : 81.16431132672432,    Ethnicity Accuracy : 59.52858046825564\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [3/30]: 100%|██████████| 297/297 [05:16<00:00,  1.07s/it, loss=2.2] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 3/30,    Age Accuracy : 42.52267454123603,    Gender Accuracy : 85.27736764395696,    Ethnicity Accuracy : 69.76376291921535\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [4/30]: 100%|██████████| 297/297 [05:40<00:00,  1.15s/it, loss=2.08]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 4/30,    Age Accuracy : 45.36490191942628,    Gender Accuracy : 88.061590381776,    Ethnicity Accuracy : 73.88209238557266\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [5/30]: 100%|██████████| 297/297 [05:41<00:00,  1.15s/it, loss=2.32]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 5/30,    Age Accuracy : 47.305420797300144,    Gender Accuracy : 88.91584053997047,    Ethnicity Accuracy : 76.58194473739718\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [6/30]: 100%|██████████| 297/297 [14:25<00:00,  2.91s/it, loss=2.14]   \n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 6/30,    Age Accuracy : 49.103564648808266,    Gender Accuracy : 90.33431765450327,    Ethnicity Accuracy : 78.62792659776419\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [7/30]: 100%|██████████| 297/297 [05:40<00:00,  1.15s/it, loss=2.59]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 7/30,    Age Accuracy : 50.46931027209449,    Gender Accuracy : 91.61569289179498,    Ethnicity Accuracy : 80.71609365112845\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [8/30]: 100%|██████████| 297/297 [05:38<00:00,  1.14s/it, loss=2.14]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 8/30,    Age Accuracy : 52.11980594811221,    Gender Accuracy : 92.41721155874288,    Ethnicity Accuracy : 82.08711242353934\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [9/30]: 100%|██████████| 297/297 [05:44<00:00,  1.16s/it, loss=1.56]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 9/30,    Age Accuracy : 54.34507487871757,    Gender Accuracy : 93.0447163045771,    Ethnicity Accuracy : 83.769246994305\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [10/30]: 100%|██████████| 297/297 [05:46<00:00,  1.17s/it, loss=1.39]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 10/30,    Age Accuracy : 55.44716304577093,    Gender Accuracy : 93.76713773465514,    Ethnicity Accuracy : 85.34591858257753\n","\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/297 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Saving Checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [11/30]: 100%|██████████| 297/297 [05:38<00:00,  1.14s/it, loss=1.13]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 11/30,    Age Accuracy : 57.888631090487245,    Gender Accuracy : 94.76376291921535,    Ethnicity Accuracy : 86.64838641636786\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [12/30]: 100%|██████████| 297/297 [05:37<00:00,  1.14s/it, loss=2.05]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 12/30,    Age Accuracy : 60.28264079308163,    Gender Accuracy : 95.30162412993039,    Ethnicity Accuracy : 87.99303944315545\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [13/30]: 100%|██████████| 297/297 [05:39<00:00,  1.14s/it, loss=1.52] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 13/30,    Age Accuracy : 62.191520776207554,    Gender Accuracy : 96.1400548407509,    Ethnicity Accuracy : 89.45370175068551\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [14/30]: 100%|██████████| 297/297 [05:35<00:00,  1.13s/it, loss=0.778]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 14/30,    Age Accuracy : 65.58215566336216,    Gender Accuracy : 96.34570765661253,    Ethnicity Accuracy : 90.49778527736765\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [15/30]: 100%|██████████| 297/297 [05:37<00:00,  1.14s/it, loss=1.26] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 15/30,    Age Accuracy : 67.88124868171272,    Gender Accuracy : 96.90466146382619,    Ethnicity Accuracy : 92.22737819025522\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [16/30]: 100%|██████████| 297/297 [05:37<00:00,  1.14s/it, loss=1.44] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 16/30,    Age Accuracy : 70.89221683189201,    Gender Accuracy : 97.0892216831892,    Ethnicity Accuracy : 92.77051255009492\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [17/30]: 100%|██████████| 297/297 [05:54<00:00,  1.19s/it, loss=0.725]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 17/30,    Age Accuracy : 72.89601349926176,    Gender Accuracy : 97.34760599029741,    Ethnicity Accuracy : 93.69858679603459\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [18/30]: 100%|██████████| 297/297 [06:55<00:00,  1.40s/it, loss=1.14] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 18/30,    Age Accuracy : 75.67496308795613,    Gender Accuracy : 97.87492090276314,    Ethnicity Accuracy : 94.5370175068551\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [19/30]: 100%|██████████| 297/297 [37:31<00:00,  7.58s/it, loss=0.469]   \n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 19/30,    Age Accuracy : 79.05505167686142,    Gender Accuracy : 98.18076355199325,    Ethnicity Accuracy : 95.21198059481122\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [20/30]: 100%|██████████| 297/297 [07:49<00:00,  1.58s/it, loss=0.831]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 20/30,    Age Accuracy : 80.1307740982915,    Gender Accuracy : 98.19130985024258,    Ethnicity Accuracy : 95.64965197215777\n","\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/297 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Saving Checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [21/30]: 100%|██████████| 297/297 [07:57<00:00,  1.61s/it, loss=0.624]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 21/30,    Age Accuracy : 82.56169584475849,    Gender Accuracy : 98.35477747310694,    Ethnicity Accuracy : 96.22969837587007\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [22/30]: 100%|██████████| 297/297 [08:47<00:00,  1.78s/it, loss=0.359]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 22/30,    Age Accuracy : 84.13836743303101,    Gender Accuracy : 98.5446108415946,    Ethnicity Accuracy : 96.49862898122758\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [23/30]: 100%|██████████| 297/297 [08:01<00:00,  1.62s/it, loss=0.497]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 23/30,    Age Accuracy : 85.19827040708712,    Gender Accuracy : 98.74499050833158,    Ethnicity Accuracy : 96.68318920059059\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [24/30]: 100%|██████████| 297/297 [08:01<00:00,  1.62s/it, loss=0.135]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 24/30,    Age Accuracy : 87.43408563594178,    Gender Accuracy : 98.7397173592069,    Ethnicity Accuracy : 97.05758278844125\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [25/30]: 100%|██████████| 297/297 [10:52<00:00,  2.20s/it, loss=0.486]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 25/30,    Age Accuracy : 87.94030795190888,    Gender Accuracy : 98.95591647331786,    Ethnicity Accuracy : 97.09449483231386\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [26/30]: 100%|██████████| 297/297 [06:06<00:00,  1.23s/it, loss=0.291]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 26/30,    Age Accuracy : 89.37987766294032,    Gender Accuracy : 98.96118962244252,    Ethnicity Accuracy : 97.8538283062645\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [27/30]: 100%|██████████| 297/297 [05:58<00:00,  1.21s/it, loss=0.588]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 27/30,    Age Accuracy : 89.71208605779371,    Gender Accuracy : 99.06137945581101,    Ethnicity Accuracy : 97.60599029740561\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [28/30]: 100%|██████████| 297/297 [05:03<00:00,  1.02s/it, loss=0.328]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 28/30,    Age Accuracy : 90.7245306897279,    Gender Accuracy : 99.11411094705758,    Ethnicity Accuracy : 97.69036068340013\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [29/30]: 100%|██████████| 297/297 [03:21<00:00,  1.47it/s, loss=0.551]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 29/30,    Age Accuracy : 91.40476692680869,    Gender Accuracy : 98.97173592069184,    Ethnicity Accuracy : 97.75891162202068\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [30/30]: 100%|██████████| 297/297 [03:21<00:00,  1.48it/s, loss=0.451] "]},{"name":"stdout","output_type":"stream","text":["Epoch : 30/30,    Age Accuracy : 91.77916051465935,    Gender Accuracy : 98.99282851719047,    Ethnicity Accuracy : 97.70090698164944\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["'''\n","train the model\n","''' \n","# Load hyperparameters\n","learning_rate = hyperparameters['learning_rate']\n","num_epoch = hyperparameters['epochs']\n","\n","# Define loss functions\n","age_loss = nn.CrossEntropyLoss()\n","gen_loss = nn.CrossEntropyLoss() # TODO : Explore using Binary Cross Entropy Loss?\n","eth_loss = nn.CrossEntropyLoss()\n","\n","# Define optimizer\n","opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","for epoch in range(num_epoch):\n","  # Construct tqdm loop to keep track of training\n","  loop = tqdm(enumerate(trainloader), total=len(trainloader), position=0, leave=True)\n","  age_correct, gen_correct, eth_correct, total = 0,0,0,0\n","\n","  # save the model every 10 epochs\n","  if epoch % 10 == 0:\n","    checkpoint = {'state_dict' : model.state_dict(), 'optimizer' : opt.state_dict(), \n","                  'age_loss' : age_loss, 'gen_loss' : gen_loss, 'eth_loss' : eth_loss}\n","    save_checkpoint(checkpoint, epoch)\n","\n","  # Loop through dataLoader\n","  for _, (X,y) in loop:\n","    # Unpack y to get true age, eth, and gen values\n","    # Have to do some special changes to age label to make it compatible with NN output and Loss function\n","    #age, gen, eth = y[:,0].resize_(len(y[:,0]),1).float().to(device), y[:,1].to(device), y[:,2].to(device)\n","    age, gen, eth = y[:,0].to(device), y[:,1].to(device), y[:,2].to(device)\n","    X = X.to(device)\n","    pred = model(X)          # Forward pass\n","    loss = age_loss(pred[0],age) + gen_loss(pred[1],gen) + eth_loss(pred[2],eth)   # Loss calculation\n","\n","    # Backpropagation\n","    opt.zero_grad()          # Zero the gradient\n","    loss.backward()          # Calculate updates\n","\n","    # Gradient Descent\n","    opt.step()               # Apply updates\n","\n","    # Update num correct and total\n","    age_correct += (pred[0].argmax(1) == age).type(torch.float).sum().item()\n","    gen_correct += (pred[1].argmax(1) == gen).type(torch.float).sum().item()\n","    eth_correct += (pred[2].argmax(1) == eth).type(torch.float).sum().item()\n","\n","    total += len(y)\n","\n","    # Update progress bar\n","    loop.set_description(f\"Epoch [{epoch+1}/{num_epoch}]\")\n","    loop.set_postfix(loss = loss.item())\n","\n","  # Update epoch accuracy\n","  gen_acc, eth_acc, age_acc = gen_correct/total, eth_correct/total, age_correct/total\n","\n","  # print out accuracy and loss for epoch\n","  print(f'Epoch : {epoch+1}/{num_epoch},    Age Accuracy : {age_acc*100},    Gender Accuracy : {gen_acc*100},    Ethnicity Accuracy : {eth_acc*100}\\n')"]},{"cell_type":"markdown","metadata":{"id":"F9sxKcPyNLxg"},"source":["<br> <br>\n","Now I am going to test the model"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":859,"status":"ok","timestamp":1624054785585,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"lKD70kYxPUvl","outputId":"c5a38afd-98e6-4ba4-f456-eb2dfe0de780"},"outputs":[{"name":"stdout","output_type":"stream","text":["Age Accuracy : 46.551360472474165%,     Gender Accuracy : 88.63109048723898,    Ethnicity Accuracy : 73.52879139422063\n","\n"]}],"source":["test(testloader, model)"]},{"cell_type":"markdown","metadata":{"id":"WR8_D6ERNWln"},"source":["As you can see the testing accuracy is not that great. My hypothesis is that predicting age is actually a very difficult task because there is so much variation between how people age.\n","<br> <br> \n","Even between different genders and ethnicities there is so much variance. Therefore, we have both inter and intra-variance when it comes to age.\n","<br> <br>\n","Perhaps a better approach would be to feed the outputs of the gender and ethnicity classifier to the age classifier so it can use that information as well. But, that's a project for another day."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Image 1: Age - 0, Gender - 1, Ethnicity - 2\n","Image 2: Age - 0, Gender - 1, Ethnicity - 4\n","Image 3: Age - 2, Gender - 0, Ethnicity - 0\n","Image 4: Age - 4, Gender - 1, Ethnicity - 2\n","Image 5: Age - 8, Gender - 0, Ethnicity - 0\n"]}],"source":["from PIL import Image\n","\n","\n","# Define a new dataset class for the new images\n","class NewDataset(Dataset):\n","    def __init__(self, image_paths, transform=None):\n","        self.image_paths = image_paths\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, index):\n","        image_path = self.image_paths[index]\n","        image = Image.open(image_path).convert('RGB')  # Convert to RGB if needed\n","        if self.transform:\n","            image = self.transform(image)\n","        return image\n","\n","# Example image paths\n","image_paths = ['../image1.jpg', '../image4.jpg','../image19.jpg', '../image26.jpg', '../image75.jpg']\n","\n","# Define transformations for the new images\n","new_transform = transforms.Compose([\n","    transforms.Resize((48, 48)),  # Resize to match model input size\n","    transforms.Grayscale(num_output_channels=1),  # Convert images to grayscale\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.49,), (0.23,))\n","])\n","\n","\n","# Create a new dataset for the new images\n","new_dataset = NewDataset(image_paths, transform=new_transform)\n","\n","# Create a DataLoader for the new dataset\n","new_dataloader = DataLoader(new_dataset, batch_size=5, shuffle=False)\n","\n","# Test the model on the new images\n","model.eval()\n","\n","with torch.no_grad():\n","    for images in new_dataloader:\n","        images = images.to(device)\n","        age_preds, gen_preds, eth_preds = model(images)\n","        \n","        # Convert predictions to labels\n","        age_labels = age_preds.argmax(dim=1)\n","        gen_labels = gen_preds.argmax(dim=1)\n","        eth_labels = eth_preds.argmax(dim=1)\n","        \n","        # Print the predictions for each image\n","        for i in range(len(age_labels)):\n","            print(f\"Image {i+1}: Age - {age_labels[i]}, Gender - {gen_labels[i]}, Ethnicity - {eth_labels[i]}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMwy8EJP0FeZjhJgqMk7Yvj","collapsed_sections":[],"name":"TrainTridentMain.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
